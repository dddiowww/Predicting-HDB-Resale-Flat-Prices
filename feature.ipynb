{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get all the different addresses\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"data/train_origin.csv\")\n",
    "test = pd.read_csv(\"data/test_origin.csv\")\n",
    "\n",
    "for df in [train, test]:\n",
    "    df[\"address\"] = (df[\"BLOCK\"].astype(str).str.strip() + \" \" +\n",
    "                     df[\"STREET\"].astype(str).str.strip()).str.upper()\n",
    "\n",
    "train_addr = set(train[\"address\"].unique())\n",
    "test_addr = set(test[\"address\"].unique())\n",
    "\n",
    "union_addr = sorted(train_addr.union(test_addr))\n",
    "\n",
    "union_df = pd.DataFrame({\"address\": union_addr})\n",
    "union_df.to_csv(\"union_address.csv\", index=False)\n",
    "\n",
    "print(\"file saved: union_address.csv\")\n",
    "print(union_df.head())"
   ],
   "id": "a24eff84aba9de3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get corresponding coordinates using Google API\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "GOOGLE_KEY = \"xxx\"\n",
    "\n",
    "def get_coords_google(address):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params = {\n",
    "        \"address\": address + \", Singapore\",\n",
    "        \"key\": GOOGLE_KEY\n",
    "    }\n",
    "    res = requests.get(url, params=params)\n",
    "    data = res.json()\n",
    "\n",
    "    if data.get(\"status\") == \"OK\":\n",
    "        loc = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "        return loc[\"lat\"], loc[\"lng\"]\n",
    "    else:\n",
    "        print(\"address not found:\", address, \"| status:\", data.get(\"status\"))\n",
    "        return None, None\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"union_addresses.csv\")\n",
    "\n",
    "latitudes, longitudes = [], []\n",
    "\n",
    "for i, street in enumerate(df[\"address\"], start=1):\n",
    "    lat, lng = get_coords_google(street)\n",
    "    latitudes.append(lat)\n",
    "    longitudes.append(lng)\n",
    "    print(f\"{i}/{len(df)} {street}: ({lat}, {lng})\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "df[\"LATITUDE\"] = latitudes\n",
    "df[\"LONGITUDE\"] = longitudes\n",
    "\n",
    "df.to_csv(\"address_with_coords.csv\", index=False)\n",
    "print(\"file saved: address_with_coords.csv\")\n"
   ],
   "id": "685b68743d3ca6eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# add the coordinates to train and test tables\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_addr = pd.read_csv(\"address_with_coords.csv\")\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "    df[\"BLOCK_UPPER\"] = df[\"BLOCK\"].astype(str).str.upper()\n",
    "    df[\"STREET_UPPER\"] = df[\"STREET\"].str.upper()\n",
    "    df[\"address\"] = df[\"BLOCK_UPPER\"] + \" \" + df[\"STREET_UPPER\"]\n",
    "\n",
    "df_addr[\"address\"] = df_addr[\"address\"].str.upper()\n",
    "\n",
    "df_train = df_train.merge(df_addr, on=\"address\", how=\"left\")\n",
    "df_test = df_test.merge(df_addr, on=\"address\", how=\"left\")\n",
    "\n",
    "df_train.to_csv(\"train_with_coords.csv\", index=False)\n",
    "df_test.to_csv(\"test_with_coords.csv\", index=False)\n",
    "print(\"file savedï¼štrain_with_coords.csv / test_with_coords.csv\")\n"
   ],
   "id": "583e6cf28b9b1279",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate the distances of 5 nearest facilities to every hdb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_train = pd.read_csv(\"train_with_coords.csv\")\n",
    "df_test = pd.read_csv(\"test_with_coords.csv\")\n",
    "\n",
    "facilities = {\n",
    "    \"PRIMARY\": pd.read_csv(\"auxiliary-data/sg-primary-schools.csv\"),\n",
    "    \"SECONDARY\": pd.read_csv(\"auxiliary-data/sg-secondary-schools.csv\"),\n",
    "    \"MALL\": pd.read_csv(\"auxiliary-data/sg-shopping-malls.csv\"),\n",
    "    \"MRT\": pd.read_csv(\"auxiliary-data/sg-mrt-stations.csv\"),\n",
    "    \"HAWKER\": pd.read_csv(\"auxiliary-data/sg-gov-hawkers.csv\")\n",
    "}\n",
    "\n",
    "def euclidean_km(lat1, lon1, lat2, lon2):\n",
    "    return 111 * np.sqrt((lat1 - lat2)**2 + (lon1 - lon2)**2)\n",
    "\n",
    "def add_topk_facility_distances(df, facility_df, prefix, k=5):\n",
    "    print(f\"Processing {prefix} ...\")\n",
    "    facility_coords = facility_df[[\"LATITUDE\", \"LONGITUDE\"]].values\n",
    "    topk_cols = [f\"DIST_{prefix}_{i+1}\" for i in range(k)]\n",
    "    topk_matrix = np.zeros((len(df), k))\n",
    "\n",
    "    for idx, (lat, lon) in tqdm(\n",
    "        enumerate(zip(df[\"LATITUDE\"], df[\"LONGITUDE\"])),\n",
    "        total=len(df),\n",
    "        desc=f\"{prefix} distances\"\n",
    "    ):\n",
    "        distances = euclidean_km(lat, lon, facility_coords[:, 0], facility_coords[:, 1])\n",
    "        topk = np.sort(distances)[:k]\n",
    "        if len(topk) < k:\n",
    "            topk = np.pad(topk, (0, k - len(topk)), constant_values=topk[-1])\n",
    "        topk_matrix[idx, :] = topk\n",
    "\n",
    "    for i in range(k):\n",
    "        df[topk_cols[i]] = topk_matrix[:, i]\n",
    "\n",
    "    return df\n",
    "\n",
    "for name, df_fac in facilities.items():\n",
    "    df_train = add_topk_facility_distances(df_train, df_fac, name, k=5)\n",
    "    df_test = add_topk_facility_distances(df_test, df_fac, name, k=5)\n",
    "\n",
    "df_train.to_csv(\"train_5.csv\", index=False)\n",
    "df_test.to_csv(\"test_5.csv\", index=False)\n",
    "\n",
    "print(\"file saved: train_5.csv / test_5.csv\")\n",
    "\n"
   ],
   "id": "a60aaa5a19f21fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# normalize the distances just calculated\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"train_5.csv\")\n",
    "df_test = pd.read_csv(\"test_5.csv\")\n",
    "\n",
    "start_col = \"DIST_MRT_MIN\"\n",
    "end_col = \"DIST_HAWKER_MIN\"\n",
    "\n",
    "start_idx = df_train.columns.get_loc(start_col)\n",
    "end_idx = df_train.columns.get_loc(end_col) + 1\n",
    "cols_to_drop = df_train.columns[start_idx:end_idx]\n",
    "\n",
    "df_train = df_train.drop(columns=cols_to_drop)\n",
    "df_test = df_test.drop(columns=cols_to_drop)\n",
    "\n",
    "dist_cols = [c for c in df_train.columns if c.startswith(\"DIST_\")]\n",
    "\n",
    "for col in dist_cols:\n",
    "    d_min = min(df_train[col].min(), df_test[col].min())\n",
    "    d_max = max(df_train[col].max(), df_test[col].max())\n",
    "    if d_max == d_min:\n",
    "        df_train[col] = 1.0\n",
    "        df_test[col] = 1.0\n",
    "    else:\n",
    "        df_train[col] = 1 - (df_train[col] - d_min) / (d_max - d_min)\n",
    "        df_test[col] = 1 - (df_test[col] - d_min) / (d_max - d_min)\n",
    "\n",
    "df_train.to_csv(\"train_5_norm.csv\", index=False)\n",
    "df_test.to_csv(\"test_5_norm.csv\", index=False)\n",
    "\n",
    "print(\"file saved: train_5_norm.csv / test_5_norm.csv\")\n"
   ],
   "id": "cbfdbe67ed26a09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get region map\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "mrt = pd.read_csv(\"auxiliary-data/sg-mrt-stations.csv\")\n",
    "pri = pd.read_csv(\"auxiliary-data/sg-primary-schools.csv\")\n",
    "sec = pd.read_csv(\"auxiliary-data/sg-secondary-schools.csv\")\n",
    "mall = pd.read_csv(\"auxiliary-data/sg-shopping-malls.csv\")\n",
    "\n",
    "dfs = [mrt[[\"PLANNING_AREA\", \"REGION\"]],\n",
    "       pri[[\"PLANNING_AREA\", \"REGION\"]],\n",
    "       sec[[\"PLANNING_AREA\", \"REGION\"]],\n",
    "       mall[[\"PLANNING_AREA\", \"REGION\"]]]\n",
    "\n",
    "union_df = pd.concat(dfs, axis=0).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "union_df[\"PLANNING_AREA\"] = union_df[\"PLANNING_AREA\"].str.strip().str.upper()\n",
    "\n",
    "union_df = union_df.drop_duplicates(subset=[\"PLANNING_AREA\"]).reset_index(drop=True)\n",
    "\n",
    "union_df.to_csv(\"region.csv\", index=False)\n",
    "\n",
    "print(\"file saved: region.csv\")\n",
    "\n"
   ],
   "id": "9e599c7ab040a3c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# map the regions to train and test tables; then do one-hot encoding\n",
    "\n",
    "region_map = pd.read_csv(\"region.csv\")\n",
    "\n",
    "for name in [\"train_5_norm.csv\", \"test_5_norm.csv\"]:\n",
    "    df = pd.read_csv(name)\n",
    "    df[\"TOWN_UPPER\"] = df[\"TOWN\"].str.strip().str.upper()\n",
    "    df = df.merge(region_map.rename(columns={\"PLANNING_AREA\": \"TOWN_UPPER\"}),\n",
    "                  on=\"TOWN_UPPER\", how=\"left\")\n",
    "\n",
    "    df = pd.get_dummies(df, columns=[\"REGION\"], prefix=\"REGION\")\n",
    "\n",
    "    out_name = name.replace(\".csv\", \"_region.csv\")\n",
    "    df.to_csv(out_name, index=False)\n",
    "    print(f\"file saved: {out_name}\")\n"
   ],
   "id": "a39f3fa045c84745",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
